{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 â€” Build Unified Manifest (ICBHI + Fraiwan) â€” 8-Class Lung Sound Project\n",
        "\n",
        "This notebook builds a single **manifest_all.csv** and patient-wise splits (**train/val/test**) for our 8-class lung sound classification project.\n",
        "\n",
        "## âœ… Final 8 classes\n",
        "1. Normal  \n",
        "2. Asthma  \n",
        "3. COPD  \n",
        "4. Pneumonia  \n",
        "5. Bronchitis  \n",
        "6. Heart failure  \n",
        "7. Pleural effusion  \n",
        "8. Lung fibrosis  \n",
        "\n",
        "## ðŸ“Œ Datasets (local folders)\n",
        "- **ICBHI 2017** (Kaggle `vbookshelf/respiratory-sound-database`)  \n",
        "  Uses:\n",
        "  - `patient_diagnosis.csv` (patient â†’ diagnosis)\n",
        "  - `audio_and_txt_files/*.wav` (audio)\n",
        "\n",
        "- **Fraiwan** (Mendeley)  \n",
        "  Uses:\n",
        "  - `audio/*.wav` (audio)\n",
        "  - (Optional for inspection) `Data annotation.xlsx`\n",
        "\n",
        "## Important design choices\n",
        "- **Single-label classification**: Fraiwan entries with multiple diagnoses like `A + B` are **dropped**.\n",
        "- **ICBHI used only for overlapping classes**: `Healthyâ†’Normal`, `Asthma`, `COPD`, `Pneumonia` (others are dropped).\n",
        "- **Patient-wise split**: prevents leakage (same patient audio never appears in both train and test).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1 â€” Imports + (optional) dependency note\n",
        "\n",
        "from pathlib import Path\n",
        "import random\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Optional: if you want to read .xlsx (inspection only), pandas needs openpyxl.\n",
        "# If you get \"Missing optional dependency 'openpyxl'\", run:\n",
        "# !pip -q install openpyxl\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "pd.set_option(\"display.max_rows\", 50)\n",
        "pd.set_option(\"display.max_columns\", 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Paths & basic sanity checks\n",
        "\n",
        "This notebook assumes it is stored inside:\n",
        "`lung_sound_project/notebooks/01_build_manifest.ipynb`\n",
        "\n",
        "So the project root is one folder up from the notebook folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CWD: /teamspace/studios/this_studio/lung_sound_project/notebooks\n",
            "PROJECT_ROOT: /teamspace/studios/this_studio/lung_sound_project\n",
            "\n",
            "ICBHI_ROOT exists: True\n",
            "ICBHI_AUDIO_DIR exists: True\n",
            "ICBHI_DIAG_CSV exists: True\n",
            "\n",
            "FRAIWAN_AUDIO_DIR exists: True\n",
            "FRAIWAN_XLSX exists: True\n"
          ]
        }
      ],
      "source": [
        "# Cell 2 â€” Resolve project root & dataset locations\n",
        "\n",
        "CWD = Path.cwd().resolve()         # .../lung_sound_project/notebooks\n",
        "PROJECT_ROOT = CWD.parents[0]      # .../lung_sound_project\n",
        "\n",
        "# ICBHI (Kaggle vbookshelf/respiratory-sound-database)\n",
        "ICBHI_ROOT = PROJECT_ROOT / \"data/raw/icbhi/ICBHI_final_database\"\n",
        "ICBHI_AUDIO_DIR = ICBHI_ROOT / \"audio_and_txt_files\"\n",
        "ICBHI_DIAG_CSV = ICBHI_ROOT / \"patient_diagnosis.csv\"\n",
        "\n",
        "# Fraiwan (Mendeley)\n",
        "FRAIWAN_AUDIO_DIR = PROJECT_ROOT / \"data/raw/fraiwan/audio\"\n",
        "FRAIWAN_XLSX = PROJECT_ROOT / \"data/raw/fraiwan/Data annotation.xlsx\"  # optional inspection\n",
        "\n",
        "# Outputs\n",
        "OUT_DIR = PROJECT_ROOT / \"data/processed/manifests\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"CWD:\", CWD)\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "\n",
        "print(\"\\nICBHI_ROOT exists:\", ICBHI_ROOT.exists())\n",
        "print(\"ICBHI_AUDIO_DIR exists:\", ICBHI_AUDIO_DIR.exists())\n",
        "print(\"ICBHI_DIAG_CSV exists:\", ICBHI_DIAG_CSV.exists())\n",
        "\n",
        "print(\"\\nFRAIWAN_AUDIO_DIR exists:\", FRAIWAN_AUDIO_DIR.exists())\n",
        "print(\"FRAIWAN_XLSX exists:\", FRAIWAN_XLSX.exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ICBHI wav count: 920\n",
            "Fraiwan wav count: 336\n",
            "\n",
            "Example ICBHI file: 101_1b1_Al_sc_Meditron.wav\n",
            "Example Fraiwan file: BP100_N,N,P R M,70,F.wav\n"
          ]
        }
      ],
      "source": [
        "# Cell 3 â€” Count audio files (sanity check)\n",
        "\n",
        "icbhi_wavs = sorted(ICBHI_AUDIO_DIR.glob(\"*.wav\")) if ICBHI_AUDIO_DIR.exists() else []\n",
        "fraiwan_wavs = sorted(FRAIWAN_AUDIO_DIR.glob(\"*.wav\")) if FRAIWAN_AUDIO_DIR.exists() else []\n",
        "\n",
        "print(\"ICBHI wav count:\", len(icbhi_wavs))     # expected ~920\n",
        "print(\"Fraiwan wav count:\", len(fraiwan_wavs)) # expected ~336\n",
        "\n",
        "print(\"\\nExample ICBHI file:\", icbhi_wavs[0].name if icbhi_wavs else \"N/A\")\n",
        "print(\"Example Fraiwan file:\", fraiwan_wavs[0].name if fraiwan_wavs else \"N/A\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Label mapping (8-class design)\n",
        "\n",
        "### ICBHI (keep only 4 classes)\n",
        "- Healthy â†’ Normal  \n",
        "- Asthma â†’ Asthma  \n",
        "- COPD â†’ COPD  \n",
        "- Pneumonia â†’ Pneumonia  \n",
        "All other ICBHI diagnoses are dropped (URTI/LRTI/Bronchiectasis/etc.)\n",
        "\n",
        "### Fraiwan\n",
        "We parse diagnosis from the filename pattern:\n",
        "`<PATIENTID>_<DIAGNOSIS>,...wav`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4 â€” Define final 8 classes and normalization helpers\n",
        "\n",
        "EIGHT_CLASSES = [\n",
        "    \"Normal\",\n",
        "    \"Asthma\",\n",
        "    \"COPD\",\n",
        "    \"Pneumonia\",\n",
        "    \"Bronchitis\",\n",
        "    \"Heart failure\",\n",
        "    \"Pleural effusion\",\n",
        "    \"Lung fibrosis\",\n",
        "]\n",
        "\n",
        "label_to_id = {lbl: i for i, lbl in enumerate(EIGHT_CLASSES)}\n",
        "id_to_label = {i: lbl for lbl, i in label_to_id.items()}\n",
        "\n",
        "def normalize_label(raw: str):\n",
        "    \"\"\"Normalize raw label strings into one of the 8 final classes, else None.\"\"\"\n",
        "    s = (raw or \"\").strip().lower()\n",
        "    s = \" \".join(s.split())\n",
        "\n",
        "    if s in {\"n\", \"normal\", \"healthy\"}:\n",
        "        return \"Normal\"\n",
        "    if s == \"asthma\":\n",
        "        return \"Asthma\"\n",
        "    if s == \"copd\":\n",
        "        return \"COPD\"\n",
        "    if s == \"pneumonia\":\n",
        "        return \"Pneumonia\"\n",
        "    if s == \"bronchitis\":\n",
        "        return \"Bronchitis\"\n",
        "    if s in {\"heart failure\", \"heartfailure\"}:\n",
        "        return \"Heart failure\"\n",
        "    if s in {\"pleural effusion\", \"pleuraleffusion\"}:\n",
        "        return \"Pleural effusion\"\n",
        "    if s in {\"lung fibrosis\", \"lungfibrosis\", \"pulmonary fibrosis\"}:\n",
        "        return \"Lung fibrosis\"\n",
        "    return None\n",
        "\n",
        "def icbhi_to_final(label: str):\n",
        "    \"\"\"Map ICBHI diagnosis labels to our final labels (only 4 kept).\"\"\"\n",
        "    if label == \"Healthy\":\n",
        "        return \"Normal\"\n",
        "    if label in {\"Asthma\", \"COPD\", \"Pneumonia\"}:\n",
        "        return label\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Fraiwan rows (single-label only)\n",
        "\n",
        "We:\n",
        "1. Read each `.wav` in `data/raw/fraiwan/audio`\n",
        "2. Extract patient_id and diagnosis from filename\n",
        "3. Drop multi-diagnosis samples containing `+`\n",
        "4. Normalize label to our 8 classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fraiwan total wav: 336\n",
            "Fraiwan rows kept: 309\n",
            "Dropped multi-diagnosis (+): 9\n",
            "Bad filename pattern: 0\n",
            "Unknown diagnosis tokens (sample): ['Asthma and lung fibrosis', 'BRON', 'Plueral Effusion']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "label\n",
              "Normal           105\n",
              "Asthma            96\n",
              "Heart failure     54\n",
              "COPD              27\n",
              "Pneumonia         15\n",
              "Lung fibrosis     12\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cell 5 â€” Build Fraiwan manifest rows from filenames\n",
        "\n",
        "fraiwan_rows = []\n",
        "fraiwan_unknown = []\n",
        "fraiwan_multi_diag = 0\n",
        "fraiwan_bad_name = 0\n",
        "\n",
        "for wav_path in sorted(FRAIWAN_AUDIO_DIR.glob(\"*.wav\")):\n",
        "    stem = wav_path.stem  # name without extension\n",
        "    if \"_\" not in stem:\n",
        "        fraiwan_bad_name += 1\n",
        "        continue\n",
        "\n",
        "    pid, rest = stem.split(\"_\", 1)              # BP101, Asthma,E W,P L M,12,F\n",
        "    diag_raw = rest.split(\",\", 1)[0].strip()    # Asthma / COPD / N / Lung Fibrosis / ...\n",
        "\n",
        "    # Drop multi-diagnosis cases for single-label classification\n",
        "    if \"+\" in diag_raw:\n",
        "        fraiwan_multi_diag += 1\n",
        "        continue\n",
        "\n",
        "    label = normalize_label(diag_raw)\n",
        "    if label is None:\n",
        "        fraiwan_unknown.append(diag_raw)\n",
        "        continue\n",
        "\n",
        "    fraiwan_rows.append({\n",
        "        \"filepath\": str(wav_path),\n",
        "        \"dataset\": \"fraiwan\",\n",
        "        \"patient_id\": f\"fraiwan_{pid}\",\n",
        "        \"label\": label,\n",
        "    })\n",
        "\n",
        "fraiwan_df = pd.DataFrame(fraiwan_rows)\n",
        "\n",
        "print(\"Fraiwan total wav:\", len(list(FRAIWAN_AUDIO_DIR.glob(\"*.wav\"))))\n",
        "print(\"Fraiwan rows kept:\", len(fraiwan_df))\n",
        "print(\"Dropped multi-diagnosis (+):\", fraiwan_multi_diag)\n",
        "print(\"Bad filename pattern:\", fraiwan_bad_name)\n",
        "print(\"Unknown diagnosis tokens (sample):\", sorted(set(fraiwan_unknown))[:20])\n",
        "\n",
        "fraiwan_df[\"label\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) ICBHI rows\n",
        "\n",
        "We:\n",
        "1. Load `patient_diagnosis.csv` (patient_id, diagnosis)\n",
        "2. Map diagnosis using `icbhi_to_final` (keep only 4 classes)\n",
        "3. For each `.wav`, read patient_id from filename prefix (e.g., `101_...wav` â†’ `101`)\n",
        "4. Join to get label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ICBHI total wav: 920\n",
            "ICBHI rows kept: 866\n",
            "ICBHI skipped (non-overlap diagnoses): 54\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "label\n",
              "COPD         793\n",
              "Pneumonia     37\n",
              "Normal        35\n",
              "Asthma         1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cell 6 â€” Build ICBHI rows using patient_diagnosis.csv + wav filenames\n",
        "\n",
        "# CSV has no header: pid, diagnosis\n",
        "diag = pd.read_csv(ICBHI_DIAG_CSV, header=None, names=[\"pid\", \"diagnosis\"])\n",
        "diag[\"pid\"] = diag[\"pid\"].astype(str)\n",
        "diag[\"label\"] = diag[\"diagnosis\"].apply(icbhi_to_final)\n",
        "\n",
        "# Keep only our 4 overlapping classes\n",
        "diag = diag.dropna(subset=[\"label\"]).copy()\n",
        "diag_map = dict(zip(diag[\"pid\"], diag[\"label\"]))\n",
        "\n",
        "icbhi_rows = []\n",
        "icbhi_skipped = 0\n",
        "\n",
        "for wav_path in sorted(ICBHI_AUDIO_DIR.glob(\"*.wav\")):\n",
        "    pid = wav_path.stem.split(\"_\", 1)[0].strip()  # \"101\" from \"101_1b1_Al_sc_....wav\"\n",
        "    label = diag_map.get(pid)\n",
        "    if label is None:\n",
        "        icbhi_skipped += 1\n",
        "        continue\n",
        "\n",
        "    icbhi_rows.append({\n",
        "        \"filepath\": str(wav_path),\n",
        "        \"dataset\": \"icbhi\",\n",
        "        \"patient_id\": f\"icbhi_{pid}\",\n",
        "        \"label\": label,\n",
        "    })\n",
        "\n",
        "icbhi_df = pd.DataFrame(icbhi_rows)\n",
        "\n",
        "print(\"ICBHI total wav:\", len(list(ICBHI_AUDIO_DIR.glob(\"*.wav\"))))\n",
        "print(\"ICBHI rows kept:\", len(icbhi_df))\n",
        "print(\"ICBHI skipped (non-overlap diagnoses):\", icbhi_skipped)\n",
        "\n",
        "icbhi_df[\"label\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Combine and save `manifest_all.csv`\n",
        "\n",
        "The combined manifest has columns:\n",
        "\n",
        "- `filepath` (absolute path)\n",
        "- `dataset` (icbhi / fraiwan)\n",
        "- `patient_id` (prefixed to avoid collisions: `icbhi_101`, `fraiwan_BP101`)\n",
        "- `label` (one of 8 classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total rows: 1175\n",
            "Unique patients: 406\n",
            "\n",
            "Overall label counts:\n",
            " label\n",
            "COPD             820\n",
            "Normal           140\n",
            "Asthma            97\n",
            "Heart failure     54\n",
            "Pneumonia         52\n",
            "Lung fibrosis     12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Saved: /teamspace/studios/this_studio/lung_sound_project/data/processed/manifests/manifest_all.csv\n"
          ]
        }
      ],
      "source": [
        "# Cell 7 â€” Combine manifests and save manifest_all.csv\n",
        "\n",
        "manifest_all = pd.concat([fraiwan_df, icbhi_df], ignore_index=True)\n",
        "\n",
        "print(\"Total rows:\", len(manifest_all))\n",
        "print(\"Unique patients:\", manifest_all[\"patient_id\"].nunique())\n",
        "print(\"\\nOverall label counts:\\n\", manifest_all[\"label\"].value_counts())\n",
        "\n",
        "manifest_path = OUT_DIR / \"manifest_all.csv\"\n",
        "manifest_all.to_csv(manifest_path, index=False)\n",
        "print(\"\\nSaved:\", manifest_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Patient-wise split (train/val/test)\n",
        "\n",
        "We split by **patient_id** to prevent leakage.\n",
        "\n",
        "Default split: **70% train, 10% val, 20% test**.\n",
        "\n",
        "If a class has too few patients, we keep them in train.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows  -> train: 732 val: 152 test: 291\n",
            "Pats  -> train: 286 val: 40 test: 80\n",
            "Saved splits into: /teamspace/studios/this_studio/lung_sound_project/data/processed/manifests\n"
          ]
        }
      ],
      "source": [
        "# Cell 8 â€” Patient-wise stratified split and save train/val/test CSVs\n",
        "\n",
        "def patient_wise_split(df: pd.DataFrame, train=0.7, val=0.1, test=0.2, seed=42):\n",
        "    assert abs((train + val + test) - 1.0) < 1e-6\n",
        "\n",
        "    # Check per-patient unique label\n",
        "    per_patient = df.groupby(\"patient_id\")[\"label\"].nunique()\n",
        "    conflict = per_patient[per_patient > 1].index.tolist()\n",
        "    if conflict:\n",
        "        print(\"WARNING: Patients with multiple labels found. Dropping:\", len(conflict))\n",
        "        df = df[~df[\"patient_id\"].isin(conflict)].copy()\n",
        "\n",
        "    patient_label = df.groupby(\"patient_id\")[\"label\"].first()\n",
        "\n",
        "    # Patients grouped by label\n",
        "    by_label = {}\n",
        "    for lbl in sorted(df[\"label\"].unique()):\n",
        "        pts = patient_label[patient_label == lbl].index.tolist()\n",
        "        rnd = random.Random(seed)\n",
        "        rnd.shuffle(pts)\n",
        "        by_label[lbl] = pts\n",
        "\n",
        "    train_pts, val_pts, test_pts = set(), set(), set()\n",
        "\n",
        "    for lbl, pts in by_label.items():\n",
        "        n = len(pts)\n",
        "\n",
        "        # Too small: keep in train\n",
        "        if n < 3:\n",
        "            train_pts.update(pts)\n",
        "            continue\n",
        "\n",
        "        n_test = max(1, round(n * test))\n",
        "        n_val = max(1, round(n * val))\n",
        "        if n_test + n_val >= n:\n",
        "            n_test = max(1, n_test - 1)\n",
        "\n",
        "        test_chunk = pts[:n_test]\n",
        "        val_chunk = pts[n_test:n_test + n_val]\n",
        "        train_chunk = pts[n_test + n_val:]\n",
        "\n",
        "        test_pts.update(test_chunk)\n",
        "        val_pts.update(val_chunk)\n",
        "        train_pts.update(train_chunk)\n",
        "\n",
        "    train_df = df[df[\"patient_id\"].isin(train_pts)].reset_index(drop=True)\n",
        "    val_df   = df[df[\"patient_id\"].isin(val_pts)].reset_index(drop=True)\n",
        "    test_df  = df[df[\"patient_id\"].isin(test_pts)].reset_index(drop=True)\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "train_df, val_df, test_df = patient_wise_split(manifest_all, train=0.7, val=0.1, test=0.2, seed=SEED)\n",
        "\n",
        "print(\"Rows  -> train:\", len(train_df), \"val:\", len(val_df), \"test:\", len(test_df))\n",
        "print(\"Pats  -> train:\", train_df[\"patient_id\"].nunique(),\n",
        "      \"val:\", val_df[\"patient_id\"].nunique(),\n",
        "      \"test:\", test_df[\"patient_id\"].nunique())\n",
        "\n",
        "train_df.to_csv(OUT_DIR / \"train.csv\", index=False)\n",
        "val_df.to_csv(OUT_DIR / \"val.csv\", index=False)\n",
        "test_df.to_csv(OUT_DIR / \"test.csv\", index=False)\n",
        "\n",
        "print(\"Saved splits into:\", OUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Save label maps (for later training + Gradio inference)\n",
        "\n",
        "We store:\n",
        "- `models/label_to_id.json`\n",
        "- `models/id_to_label.json`\n",
        "\n",
        "These must remain consistent throughout training and inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: /teamspace/studios/this_studio/lung_sound_project/models/label_to_id.json\n",
            "Saved: /teamspace/studios/this_studio/lung_sound_project/models/id_to_label.json\n"
          ]
        }
      ],
      "source": [
        "# Cell 9 â€” Save label mappings for later reuse\n",
        "\n",
        "label_to_id_path = MODELS_DIR / \"label_to_id.json\"\n",
        "id_to_label_path = MODELS_DIR / \"id_to_label.json\"\n",
        "\n",
        "with open(label_to_id_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(label_to_id, f, indent=2)\n",
        "\n",
        "with open(id_to_label_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(id_to_label, f, indent=2)\n",
        "\n",
        "print(\"Saved:\", label_to_id_path)\n",
        "print(\"Saved:\", id_to_label_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Quick distribution report (for your report)\n",
        "\n",
        "We print class counts for overall + each split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "== Overall ==\n",
            "label\n",
            "COPD             820\n",
            "Normal           140\n",
            "Asthma            97\n",
            "Heart failure     54\n",
            "Pneumonia         52\n",
            "Lung fibrosis     12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "== Train ==\n",
            "label\n",
            "COPD             476\n",
            "Normal            99\n",
            "Asthma            68\n",
            "Pneumonia         42\n",
            "Heart failure     38\n",
            "Lung fibrosis      9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "== Val ==\n",
            "label\n",
            "COPD             120\n",
            "Normal            14\n",
            "Asthma            10\n",
            "Heart failure      5\n",
            "Pneumonia          2\n",
            "Lung fibrosis      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "== Test ==\n",
            "label\n",
            "COPD             224\n",
            "Normal            27\n",
            "Asthma            19\n",
            "Heart failure     11\n",
            "Pneumonia          8\n",
            "Lung fibrosis      2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Cell 10 â€” Distribution report\n",
        "\n",
        "def show_counts(name, df):\n",
        "    print(f\"\\n== {name} ==\")\n",
        "    print(df[\"label\"].value_counts())\n",
        "\n",
        "show_counts(\"Overall\", manifest_all)\n",
        "show_counts(\"Train\", train_df)\n",
        "show_counts(\"Val\", val_df)\n",
        "show_counts(\"Test\", test_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Optional: Inspect Fraiwan Excel annotations (not required for manifest)\n",
        "\n",
        "The Fraiwan Excel file does **not** map rows directly to filenames (no filename column),  \n",
        "so we use it only to understand possible multi-diagnosis patterns & label variants.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sheets: ['Sheet1']\n",
            "Shape: (154, 10)\n",
            "\n",
            "Top Diagnosis values (Excel):\n",
            "Diagnosis\n",
            "nan                               42\n",
            "N                                 35\n",
            "Asthma                            17\n",
            "heart failure                     15\n",
            "asthma                            15\n",
            "COPD                               8\n",
            "pneumonia                          5\n",
            "Lung Fibrosis                      4\n",
            "Heart Failure                      3\n",
            "BRON                               3\n",
            "Heart Failure + COPD               2\n",
            "Plueral Effusion                   2\n",
            "Heart Failure + Lung Fibrosis      1\n",
            "Asthma and lung fibrosis           1\n",
            "copd                               1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Examples with '+':\n",
            "    Age Gender                       Diagnosis\n",
            "3  72.0      F  Heart Failure + Lung Fibrosis \n",
            "4  71.0      M            Heart Failure + COPD\n",
            "6  65.0      M            Heart Failure + COPD\n"
          ]
        }
      ],
      "source": [
        "# Cell 11 (Optional) â€” Inspect Fraiwan Excel sheet\n",
        "\n",
        "if FRAIWAN_XLSX.exists():\n",
        "    try:\n",
        "        xls = pd.ExcelFile(FRAIWAN_XLSX)\n",
        "        print(\"Sheets:\", xls.sheet_names)\n",
        "        df_x = pd.read_excel(FRAIWAN_XLSX, sheet_name=xls.sheet_names[0])\n",
        "        print(\"Shape:\", df_x.shape)\n",
        "        if \"Diagnosis\" in df_x.columns:\n",
        "            print(\"\\nTop Diagnosis values (Excel):\")\n",
        "            print(df_x[\"Diagnosis\"].astype(str).value_counts().head(20))\n",
        "            print(\"\\nExamples with '+':\")\n",
        "            print(df_x[df_x[\"Diagnosis\"].astype(str).str.contains(r\"\\+\", na=False)][[\"Age\", \"Gender\", \"Diagnosis\"]].head(10))\n",
        "        else:\n",
        "            print(\"No 'Diagnosis' column found in Excel.\")\n",
        "    except Exception as e:\n",
        "        print(\"Excel read failed:\", e)\n",
        "else:\n",
        "    print(\"Excel file not found (optional).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "âœ… Done. Next notebook: **02_train_model.ipynb**  \n",
        "(Load `train.csv/val.csv/test.csv`, build mel spectrogram sequences, train DenseNet121 + LSTM, and save `best_model.pth` + `config.json`.)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
